{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import data \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "pd_train_origin_copy = pd.read_csv('train.csv').drop(columns=['diameter', 'albedo', 'diameter_sigma'])\n",
    "pd_test_origin_copy = pd.read_csv('test.csv').drop(columns=['diameter', 'albedo', 'diameter_sigma'])\n",
    "pd_train_origin_copy = pd_train_origin_copy.drop(columns = pd_train_origin_copy.columns[0])\n",
    "pd_test_origin_copy = pd_test_origin_copy.drop(columns = pd_test_origin_copy.columns[0])\n",
    "print(pd_train_origin_copy.columns.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Preparing for the knn model \"\"\"\n",
    "\n",
    "pd_train_origin = pd_train_origin_copy.copy()\n",
    "pd_test_origin = pd_test_origin_copy.copy()\n",
    "\n",
    "pd_train_corr = pd_train_origin.corr() # get a k*k matrix (k = the number of features)\n",
    "corr_result = pd_train_corr['class_num']\n",
    "#print(corr_result)\n",
    "corr_idx = pd_train_corr['class_num'].index\n",
    "\n",
    "ft = []\n",
    "drop_ft = []\n",
    "siz = corr_result.size\n",
    "\n",
    "for i in range(siz):\n",
    "    if((corr_result[i]) >= 0.27):\n",
    "        ft.append(corr_idx[i])\n",
    "\n",
    "for i in pd_train_origin.columns:\n",
    "    if(i not in ft):\n",
    "        drop_ft.append(i)\n",
    "    else:\n",
    "        pd_train_origin[i] = pd_train_origin[i].fillna(pd_train_origin[i].mean()) # Replace NaN values with the mean of the column\n",
    "        pd_test_origin[i] = pd_test_origin[i].fillna(pd_test_origin[i].mean())\n",
    "\n",
    "pd_train = pd_train_origin.drop(columns = drop_ft)\n",
    "pd_test = pd_test_origin.drop(columns = drop_ft)\n",
    "\n",
    "y_train = pd_train['class_num']\n",
    "pd_train = pd_train.drop(columns = 'class_num')\n",
    "y_test = pd_test['class_num']\n",
    "pd_test = pd_test.drop(columns = 'class_num')\n",
    "\n",
    "print(pd_train.columns)\n",
    "print(pd_train.columns.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" modify the scalar and fitting \"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_sc = scaler.fit_transform(pd_train)\n",
    "test_sc = scaler.transform(pd_test)\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "train_sc = pca.fit_transform(train_sc)\n",
    "test_sc = pca.transform(test_sc)\n",
    "\n",
    "print(train_sc.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Training the knn model \"\"\"\n",
    "from sklearn.neighbors import KDTree\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "tree = KDTree(train_sc, leaf_size=30, metric='minkowski')\n",
    "\n",
    "test_num = test_sc.shape[0]\n",
    "pred = np.empty(test_num, dtype=train_sc.dtype)\n",
    "\n",
    "k_num = 10\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "for cur in tqdm(range(0, test_num, batch_size)):\n",
    "    batch_end = min(cur+batch_size, test_num)\n",
    "    distances, idx = tree.query(test_sc[cur:batch_end], k=k_num)\n",
    "\n",
    "    for i in range(distances.shape[0]):\n",
    "        weights = 1 / (distances[i] + 1e-7)\n",
    "        label_weights = defaultdict(float)\n",
    "\n",
    "        for j in range(k_num):\n",
    "            label = y_train[idx[i][j]]\n",
    "            label_weights[label] += weights[j]\n",
    "        pred[cur+i] = max(label_weights, key=label_weights.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" print the result \"\"\"\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(y_test, pred))\n",
    "print(\"Precision:\", precision_score(y_test, pred, average='weighted'))\n",
    "print(\"Recall : \", recall_score(y_test, pred, average='weighted'))\n",
    "print(\"F1 Score : \", f1_score(y_test, pred, average='weighted'))\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" submission \"\"\"\n",
    "\n",
    "submission = pd.DataFrame({'IDX': pd_test.index.values,'Target': pred})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
